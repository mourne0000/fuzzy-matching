{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cbe02251-8480-476b-a382-ffe0460a823e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0.00862 seconds\n",
      "    ID  gender       date   age  blood_pressure  height  weight  disease   BMI\n",
      "0    1  female 2022-11-15  25.0           100.7    1.51    44.6      0.0  19.6\n",
      "1    2    male 2020-09-28  39.0           133.2    1.75    75.6      0.0  24.7\n",
      "2    3  female 2020-05-30  67.0           109.0    1.50    41.0      1.0  18.2\n",
      "3    3  female 2024-05-23  71.0           104.8    1.56    42.4      1.0  17.4\n",
      "4    3  female 2025-04-21  72.0           110.5    1.50    40.8      1.0  18.1\n",
      "5    4    male 2022-09-30  75.0           126.4    1.69    77.1      1.0  27.0\n",
      "6    4    male 2024-10-03  77.0           120.9    1.63    77.4      NaN  29.1\n",
      "7    5  female 2023-04-23  21.0           121.0     NaN    60.0      0.0   NaN\n",
      "8    5  female 2025-05-15  23.0           117.8    1.51    54.6      0.0  23.9\n",
      "9    6  female 2020-04-01  66.0            93.6    1.66    52.9      0.0  19.2\n",
      "10   6  female 2024-06-29  70.0            98.7    1.74    50.2     -1.0  16.6\n",
      "11   6  female 2025-05-07  71.0            95.2    1.73    50.6      0.0  16.9\n",
      "12   7    male 2020-02-10  53.0           150.7    1.73    77.2      0.0  25.8\n",
      "13   7    male 2021-03-08   NaN           146.0    1.71    80.1      1.0  27.4\n",
      "14   7    male 2021-03-14  54.0           149.5    1.80    77.9      NaN  24.0\n",
      "15   7     NaN 2023-06-25  56.0            20.0    1.72    78.9      1.0  26.7\n",
      "16   8     NaN 2023-12-22  39.0             NaN    1.67    77.8      1.0  27.9\n",
      "17   9    male 2020-08-26  28.0           155.9    1.46     NaN      0.0   NaN\n",
      "18   9    male 2022-07-11  30.0           153.6    1.62    76.5      0.0  29.1\n",
      "19   9    male 2025-03-24  33.0           154.4    1.58    76.5      0.0  30.6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# generate the medical diagnostic data\n",
    "start_time = time.perf_counter()\n",
    "def generate_health_dataset(\n",
    "    # generate the scale of the data set\n",
    "    num_rows=50, \n",
    "    num_unique_ids=25,\n",
    "    output_file='health_data.csv'):\n",
    "    \n",
    "    # generate gender and attributes based on gender\n",
    "    gender = np.random.choice(['male', 'female'], num_unique_ids)\n",
    "    params = {\n",
    "        'male': {\n",
    "            'blood_pressure': (140, 8, 1),\n",
    "            'height': (1.70, 0.05, 2),\n",
    "            'weight': (75, 6, 1)\n",
    "        },\n",
    "        'female': {\n",
    "            'blood_pressure': (110, 7, 1),\n",
    "            'height': (1.60, 0.05, 2),\n",
    "            'weight': (55, 5, 1)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # generate random number of visits for one same patient\n",
    "    base_ids = np.arange(1, num_unique_ids + 1)\n",
    "    repeat_counts = np.random.multinomial(num_rows, [1/num_unique_ids]*num_unique_ids)\n",
    "    ids = np.repeat(base_ids, repeat_counts)\n",
    "    \n",
    "    def generate_values(gender_arr, param_type):\n",
    "    # generate data frame of base data\n",
    "        male_params = params['male'][param_type]\n",
    "        female_params = params['female'][param_type]\n",
    "        \n",
    "        return np.where(\n",
    "            gender_arr == 'male',\n",
    "            np.random.normal(male_params[0], male_params[1], num_unique_ids).round(male_params[2]),\n",
    "            np.random.normal(female_params[0], female_params[1], num_unique_ids).round(female_params[2])\n",
    "        )\n",
    "\n",
    "    base_data = pd.DataFrame({\n",
    "        'ID': base_ids,\n",
    "        'gender': gender,\n",
    "        'base_age': np.random.randint(18, 80, num_unique_ids),\n",
    "        'base_blood_pressure': generate_values(gender, 'blood_pressure'),\n",
    "        'base_height': generate_values(gender, 'height'),\n",
    "        'base_weight': generate_values(gender, 'weight'),\n",
    "        'base_disease': np.random.randint(0, 2, num_unique_ids).astype(int)\n",
    "    })\n",
    "    df = pd.DataFrame({'ID': ids}).merge(base_data, on='ID', how='left')\n",
    "\n",
    "    # generate random data from the same patient and attributes' changes based on the date\n",
    "    date_rng = pd.date_range(start='2020-01-01', end='2025-12-31')\n",
    "    df['date'] = np.concatenate([\n",
    "        np.sort(np.random.choice(date_rng, size=count, replace=False))\n",
    "        for count in np.bincount(ids) if count > 0\n",
    "    ])\n",
    "\n",
    "    df['age'] = df['base_age'] + (df['date'].dt.year - 2020)\n",
    "\n",
    "    noise_config = {\n",
    "        'blood_pressure': (0, 3, 1),\n",
    "        'height': (0, 0.05, 2),\n",
    "        'weight': (0, 1.5, 1)\n",
    "    }\n",
    "    \n",
    "    for column in ['blood_pressure', 'height', 'weight']:\n",
    "        base_column = f'base_{column}'\n",
    "        average, standard_deviation, decimals = noise_config[column]\n",
    "        df[column] = (df[base_column] + np.random.normal(average, standard_deviation, len(df))).round(decimals)\n",
    "\n",
    "    # disease reversal possibility\n",
    "    df['disease'] = np.where(\n",
    "        np.random.rand(len(df)) < 0.2,\n",
    "        1 - df['base_disease'],\n",
    "        df['base_disease']\n",
    "    )\n",
    "\n",
    "    # delete the base fields and sort by ID and date\n",
    "    df = df.drop(columns=['base_age', 'base_blood_pressure', \n",
    "                     'base_height', 'base_weight', 'base_disease'])\n",
    "    \n",
    "    # generate 5% clearly wrong data in specific attributes\n",
    "    error_rules = {\n",
    "        'blood_pressure': lambda size: np.where(\n",
    "            np.random.rand(size) < 0.5,\n",
    "            np.random.randint(300, 500, size),\n",
    "            np.random.randint(0, 50, size)\n",
    "        ),\n",
    "        'height': lambda size: np.random.choice([-1.0, 4.5], size=size),\n",
    "        'weight': lambda size: np.random.choice([-10, 800], size=size),\n",
    "        'disease': lambda size: np.random.choice([-1, 2], size=size),\n",
    "    }\n",
    "\n",
    "    target_cols = df.columns.difference(['ID', 'gender', 'date', 'age'])\n",
    "\n",
    "    for col in target_cols:\n",
    "        mask = np.random.rand(len(df)) < 0.05\n",
    "        num_errors = mask.sum()\n",
    "        errors = error_rules[col](num_errors)\n",
    "        df.loc[mask, col] = errors\n",
    "    \n",
    "    # generate 5% random data missing\n",
    "    cols_to_missing = df.columns.difference(['ID', 'date'])\n",
    "    mask = np.random.rand(*df[cols_to_missing].shape) < 0.05\n",
    "    df[cols_to_missing] = df[cols_to_missing].mask(mask)\n",
    "\n",
    "    # calculate the BMI\n",
    "    df['BMI'] = (df.weight / (df.height ** 2)).round(1)\n",
    "\n",
    "    # sort by ID and date\n",
    "    df = df.sort_values(['ID', 'date']).reset_index(drop=True)\n",
    "\n",
    "    # save the generated data set as csv file\n",
    "    if output_file:\n",
    "        df.to_csv(\n",
    "            output_file,\n",
    "            index=False,\n",
    "            sep=',',\n",
    "            encoding='utf-8',\n",
    "            float_format='%.1f'\n",
    "        )\n",
    "    # count time\n",
    "    elapsed = time.perf_counter() - start_time\n",
    "    return df, round(elapsed, 5)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df, run_time = generate_health_dataset()\n",
    "    print(f\"total {run_time} seconds\")\n",
    "    print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "66b5cba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total run time: 0.02413 seconds\n",
      "   ID  gender       date  age  blood_pressure  height  weight  disease   BMI\n",
      "0   1  female 2022-11-15   25           100.7     1.5    44.6      0.0  19.6\n",
      "0   2    male 2020-09-28   39           133.2     1.8    75.6      0.0  24.7\n",
      "0   3  female 2020-05-30   67           109.0     1.5    41.0      1.0  18.2\n",
      "1   3  female 2024-05-23   71           104.8     1.6    42.4      1.0  17.4\n",
      "2   3  female 2025-04-21   72           110.5     1.5    40.8      1.0  18.1\n",
      "0   4    male 2022-09-30   75           126.4     1.7    77.1      1.0  27.0\n",
      "1   4    male 2024-10-03   77           120.9     1.6    77.4      NaN  29.1\n",
      "0   5  female 2023-04-23   21           121.0     NaN    60.0      0.0   NaN\n",
      "1   5  female 2025-05-15   23           117.8     1.5    54.6      0.0  23.9\n",
      "0   6  female 2020-04-01   66            93.6     1.7    52.9      0.0  19.2\n",
      "1   6  female 2024-06-29   70            98.7     1.7    50.2     -1.0  16.6\n",
      "2   6  female 2025-05-07   71            95.2     1.7    50.6      0.0  16.9\n",
      "0   7    male 2020-02-10   53           150.7     1.7    77.2      0.0  25.8\n",
      "1   7    male 2021-03-08   54           146.0     1.7    80.1      1.0  27.4\n",
      "2   7    male 2021-03-14   54           149.5     1.8    77.9      NaN  24.0\n",
      "3   7    male 2023-06-25   56            20.0     1.7    78.9      1.0  26.7\n",
      "0   9    male 2020-08-26   28           155.9     1.5     NaN      0.0   NaN\n",
      "1   9    male 2022-07-11   30           153.6     1.6    76.5      0.0  29.1\n",
      "2   9    male 2025-03-24   33           154.4     1.6    76.5      0.0  30.6\n",
      "0  10  female 2020-06-19   63            97.1     1.5    56.4      1.0  24.4\n"
     ]
    }
   ],
   "source": [
    "# correct the missing age and gender according to the same ID and date\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def correct_age_gender(df):\n",
    "# correct the gender\n",
    "    df[\"gender\"] = df.groupby(\"ID\")[\"gender\"].transform(\n",
    "    lambda x: x.fillna(x.mode()[0]) if not x.mode().empty else x\n",
    ")\n",
    "    df = df.groupby(\"ID\").filter(\n",
    "    lambda group: ~group[\"gender\"].isna().all()\n",
    ")\n",
    "# correct the age\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['year'] = df['date'].dt.year\n",
    "\n",
    "    grouped = df.groupby('ID')\n",
    "    \n",
    "    processed_dfs = []\n",
    "    \n",
    "    for id, group in grouped:\n",
    "        # group by id and sort by date and age\n",
    "        group = group.sort_values('year').reset_index(drop=True)\n",
    "        ages = group['age'].copy()\n",
    "        years = group['year']\n",
    "\n",
    "        for i in range(len(group)):\n",
    "            # scan every empty space of age, call functions to get the previous and next age of the selected one\n",
    "            if pd.isna(ages[i]):\n",
    "                prev_age, prev_year = find_previous_value(ages, years, i)\n",
    "                next_age, next_year = find_next_value(ages, years, i)\n",
    "                \n",
    "                # different cases of nearest valid information\n",
    "                if prev_age is not None and next_age is not None:\n",
    "                    year_diff = next_year - prev_year\n",
    "                    if year_diff == 0:\n",
    "                        if prev_age == next_age:\n",
    "                            ages[i] = prev_age\n",
    "                        else:\n",
    "                            ages[i] = (prev_age + next_age) // 2\n",
    "                    else:\n",
    "                        exact_age = prev_age + ((years[i] - prev_year) / year_diff) * (next_age - prev_age)\n",
    "                        ages[i] = int(round(exact_age))\n",
    "                elif prev_age is not None:\n",
    "                    ages[i] = prev_age + (years[i] - prev_year)\n",
    "                elif next_age is not None:\n",
    "                    ages[i] = next_age - (next_year - years[i])\n",
    "                    \n",
    "        # sort to find the first valid age\n",
    "        first_valid_idx = ages.first_valid_index()\n",
    "        if first_valid_idx is not None and first_valid_idx > 0:\n",
    "            first_valid_age = ages[first_valid_idx]\n",
    "            first_valid_year = years[first_valid_idx]\n",
    "            # reverse loop to get the former id without age\n",
    "            for i in range(first_valid_idx-1, -1, -1):\n",
    "                ages[i] = first_valid_age - (first_valid_year - years[i])\n",
    "\n",
    "        # sort to find the last valid age\n",
    "        last_valid_idx = ages.last_valid_index()\n",
    "        if last_valid_idx is not None and last_valid_idx < len(ages)-1:\n",
    "            last_valid_age = ages[last_valid_idx]\n",
    "            last_valid_year = years[last_valid_idx]\n",
    "            # loop to get the last id without age if needed\n",
    "            for i in range(last_valid_idx+1, len(ages)):\n",
    "                ages[i] = last_valid_age + (years[i] - last_valid_year)\n",
    "        \n",
    "        group['age'] = ages.astype('Int64')\n",
    "        processed_dfs.append(group)\n",
    "    \n",
    "    final_df = pd.concat(processed_dfs)\n",
    "    df = final_df.drop(columns=[\"year\"])\n",
    "    return df\n",
    "\n",
    "# find the nearest date and age information in the same IDs\n",
    "def find_previous_value(ages, years, current_idx):\n",
    "    for i in range(current_idx-1, -1, -1):\n",
    "        if not pd.isna(ages[i]):\n",
    "            return ages[i], years[i]\n",
    "    return None, None\n",
    "\n",
    "def find_next_value(ages, years, current_idx):\n",
    "    for i in range(current_idx+1, len(ages)):\n",
    "        if not pd.isna(ages[i]):\n",
    "            return ages[i], years[i]\n",
    "    return None, None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    total_start = time.perf_counter()\n",
    "    df = pd.read_csv(\"health_data.csv\")\n",
    "    processed_df = correct_age_gender(df)\n",
    "    processed_df.to_csv(\"processed_health_data.csv\", index=False)\n",
    "    total_end = time.perf_counter()\n",
    "    total_run_time = total_end - total_start\n",
    "    print(f\"Total run time: {total_run_time:.5f} seconds\")\n",
    "    print(processed_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8ffd7860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID  gender        date  age  blood_pressure  height  weight  disease   BMI\n",
      "0    1  female  2022-11-15   25           100.7     1.5    44.6      0.0  19.6\n",
      "1    2    male  2020-09-28   39           133.2     1.8    75.6      0.0  24.7\n",
      "2    3  female  2020-05-30   67           109.0     1.5    41.0      1.0  18.2\n",
      "3    3  female  2024-05-23   71           104.8     1.6    42.4      1.0  17.4\n",
      "4    3  female  2025-04-21   72           110.5     1.5    40.8      1.0  18.1\n",
      "5    4    male  2022-09-30   75           126.4     1.7    77.1      1.0  27.0\n",
      "8    5  female  2025-05-15   23           117.8     1.5    54.6      0.0  23.9\n",
      "9    6  female  2020-04-01   66            93.6     1.7    52.9      0.0  19.2\n",
      "11   6  female  2025-05-07   71            95.2     1.7    50.6      0.0  16.9\n",
      "12   7    male  2020-02-10   53           150.7     1.7    77.2      0.0  25.8\n",
      "13   7    male  2021-03-08   54           146.0     1.7    80.1      1.0  27.4\n",
      "17   9    male  2022-07-11   30           153.6     1.6    76.5      0.0  29.1\n",
      "18   9    male  2025-03-24   33           154.4     1.6    76.5      0.0  30.6\n",
      "19  10  female  2020-06-19   63            97.1     1.5    56.4      1.0  24.4\n",
      "22  13  female  2025-05-31   43           120.3     1.6    55.9      1.0  22.4\n",
      "24  17  female  2021-01-28   21           110.5     1.5    50.2      1.0  22.9\n",
      "26  18  female  2023-01-01   40           117.8     1.6    60.6      1.0  22.5\n",
      "27  18  female  2025-04-12   42           120.2     1.7    62.5      1.0  20.9\n",
      "28  19  female  2020-04-24   52           111.3     1.6    57.5      0.0  21.1\n",
      "29  19  female  2020-08-18   52           106.5     1.5    52.8      0.0  22.3\n"
     ]
    }
   ],
   "source": [
    "# restrict all the dataset in the correct range in order to delete rows contained wrong and missing data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"processed_health_data.csv\")\n",
    "valid_conditions = (\n",
    "    df[\"age\"].between(10, 100)\n",
    "    & df[\"height\"].between(0.5, 2.5)\n",
    "    & df[\"weight\"].between(20, 300)\n",
    "    & (df[\"blood_pressure\"].between(60, 200))\n",
    "    & df[\"disease\"].isin([0, 1])\n",
    "    & df[\"gender\"].isin([\"male\", \"female\"])\n",
    ")\n",
    "\n",
    "cleaned_df = df[valid_conditions]\n",
    "\n",
    "cleaned_df.to_csv(\"cleaned_health_data.csv\", index=False)\n",
    "print(cleaned_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1c59dd50-fc30-4280-833c-96413f9458c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def split_and_save_data(\n",
    "    file_path: str,\n",
    "    target_column: str,\n",
    "    split_conditions: dict,\n",
    ") -> None:\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    df_cleaned = df.copy()\n",
    "\n",
    "    for filename, condition_func in split_conditions.items():\n",
    "        mask = condition_func(df_cleaned[target_column])\n",
    "        split_df = df_cleaned[mask]\n",
    "        split_df.to_csv(filename, index=False)\n",
    "\n",
    "# split the data set by disease condition\n",
    "disease_conditions = {\n",
    "    \"no_disease.csv\": lambda x: x == 0,\n",
    "    \"disease.csv\": lambda x: x == 1\n",
    "}\n",
    "\n",
    "split_and_save_data(\n",
    "    file_path = \"cleaned_health_data.csv\",\n",
    "    target_column = df.columns[7],\n",
    "    split_conditions = disease_conditions,\n",
    ")\n",
    "\n",
    "# split the disease and no_disease data set by gender\n",
    "split_and_save_data(\n",
    "    file_path=\"disease.csv\",\n",
    "    target_column = df.columns[1],\n",
    "    split_conditions={\n",
    "        \"male_disease.csv\": lambda x: x == \"male\",\n",
    "        \"female_disease.csv\": lambda x: x == \"female\"\n",
    "    }\n",
    ")\n",
    "\n",
    "split_and_save_data(\n",
    "    file_path=\"no_disease.csv\",\n",
    "    target_column = df.columns[1],\n",
    "    split_conditions={\n",
    "        \"male_no_disease.csv\": lambda x: x == \"male\",\n",
    "        \"female_no_disease.csv\": lambda x: x == \"female\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1a9bf28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "df_disease = pd.read_csv(\"disease.csv\")\n",
    "df_no_disease = pd.read_csv(\"no_disease.csv\")\n",
    "\n",
    "def preprocess_data(df, features):\n",
    "    df = df.copy()\n",
    "    df['gender'] = df['gender'].map({'female': 0, 'male': 1})\n",
    "    return df[features + ['ID', 'date']]\n",
    "\n",
    "# standardization\n",
    "def standardize_features(disease_df, no_disease_df, features):\n",
    "    combined = pd.concat([disease_df[features], no_disease_df[features]])\n",
    "    mean = combined.mean()\n",
    "    std = combined.std()\n",
    "\n",
    "    disease_features = (disease_df[features] - mean) / std\n",
    "    no_disease_features = (no_disease_df[features] - mean) / std\n",
    "    return disease_features, no_disease_features\n",
    "\n",
    "# compute the weighted covariance matrix\n",
    "def compute_weighted_covariance(disease_features, no_disease_features, weights):\n",
    "\n",
    "    combined = pd.concat([disease_features, no_disease_features])\n",
    "    cov_matrix = combined.cov().values\n",
    "\n",
    "    W_matrix = np.outer(weights, weights)\n",
    "    cov_weighted = cov_matrix / W_matrix\n",
    "\n",
    "    try:\n",
    "        cov_inv = np.linalg.inv(cov_weighted)\n",
    "    except np.linalg.LinAlgError:\n",
    "        cov_inv = np.linalg.pinv(cov_weighted)\n",
    "    return cov_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94b47e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Disease ID Disease Date  no Disease ID no Disease Date  Distance\n",
      "0            3   2020-05-30             19      2020-04-24  0.467316\n",
      "1            3   2024-05-23              6      2025-05-07  0.498367\n",
      "2            3   2025-04-21             19      2020-08-18  0.645619\n",
      "3            4   2022-09-30             19      2020-10-17  0.577036\n",
      "4            7   2021-03-08             22      2020-11-18  0.211340\n",
      "5           10   2020-06-19             19      2020-12-25  0.416014\n",
      "6           13   2025-05-31              5      2025-05-15  0.281334\n",
      "7           17   2021-01-28             21      2025-06-17  0.536621\n",
      "8           18   2023-01-01             20      2023-03-02  0.530879\n",
      "9           18   2025-04-12             25      2020-04-20  0.531043\n",
      "10          21   2024-02-01              2      2020-09-28  0.234399\n",
      "Total distance: 4.92996838323383\n"
     ]
    }
   ],
   "source": [
    "def exact_matches(disease_data, no_disease_data, \n",
    "                disease_features, no_disease_features, \n",
    "                cov_inv, enable_deduplication=True):\n",
    "    matches = []\n",
    "    used_indices = set() if enable_deduplication else None\n",
    "    \n",
    "    for i in range(len(disease_data)):\n",
    "        disease_id = disease_data.iloc[i]['ID']\n",
    "        disease_date = disease_data.iloc[i]['date']\n",
    "        current_features = disease_features.iloc[i].values.reshape(1, -1)\n",
    "\n",
    "        mask = (no_disease_data['ID'] != disease_id)\n",
    "        if enable_deduplication:\n",
    "            mask &= (~no_disease_data.index.isin(used_indices))\n",
    "            \n",
    "        candidates = no_disease_data[mask]\n",
    "        if candidates.empty:\n",
    "            continue\n",
    "\n",
    "        distances = cdist(\n",
    "            current_features, \n",
    "            no_disease_features[mask], \n",
    "            metric='mahalanobis', \n",
    "            VI=cov_inv\n",
    "        )\n",
    "\n",
    "        min_idx = np.argmin(distances)\n",
    "        best_match_idx = candidates.index[min_idx]\n",
    "# record the matched results\n",
    "        record = {\n",
    "            'Disease ID': disease_id,\n",
    "            'Disease Date': disease_date,\n",
    "            'no Disease ID': no_disease_data.loc[best_match_idx, 'ID'],\n",
    "            'no Disease Date': no_disease_data.loc[best_match_idx, 'date'],\n",
    "            'Distance': distances[0, min_idx]\n",
    "        }\n",
    "        matches.append(record)\n",
    "\n",
    "        if enable_deduplication:\n",
    "            used_indices.add(best_match_idx)\n",
    "            \n",
    "    return pd.DataFrame(matches)\n",
    "\n",
    "def main():\n",
    "\n",
    "    features = ['age', 'gender', 'blood_pressure', 'height', 'weight', 'BMI']\n",
    "    weights = np.array([0.2, 0.1, 0.3, 0.1, 0.1, 0.2])\n",
    "    output_path = \"exact_match.csv\"\n",
    "\n",
    "    X_disease = preprocess_data(df_disease, features)\n",
    "    X_no_disease = preprocess_data(df_no_disease, features)\n",
    "\n",
    "    disease_features, no_disease_features = standardize_features(\n",
    "        X_disease, X_no_disease, features\n",
    "    )\n",
    "\n",
    "    cov_inv = compute_weighted_covariance(\n",
    "        disease_features, no_disease_features, weights\n",
    "    )\n",
    "\n",
    "    matches_df = exact_matches(\n",
    "        disease_data=X_disease,\n",
    "        no_disease_data=X_no_disease,\n",
    "        disease_features=disease_features,\n",
    "        no_disease_features=no_disease_features,\n",
    "        cov_inv=cov_inv,\n",
    "        enable_deduplication=True\n",
    "    )\n",
    "\n",
    "    matches_df.to_csv(output_path, index=False)\n",
    "    print(matches_df.head(20))\n",
    "\n",
    "    total_distance = matches_df['Distance'].sum()\n",
    "    print(\"Total distance:\", total_distance)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d992c408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Disease ID Disease Date  no Disease ID no Disease Date  Distance\n",
      "0            3   2020-05-30              5      2025-05-15  0.990307\n",
      "1            3   2024-05-23              9      2025-03-24  2.345014\n",
      "2            3   2025-04-21              9      2022-07-11  1.951586\n",
      "3            4   2022-09-30              7      2020-02-10  1.017205\n",
      "4            7   2021-03-08             19      2020-12-25  1.315722\n",
      "5           10   2020-06-19             22      2025-07-19  1.748595\n",
      "6           13   2025-05-31             20      2023-03-02  0.586361\n",
      "7           17   2021-01-28             19      2020-08-18  0.493180\n",
      "8           18   2023-01-01             19      2020-10-17  0.530515\n",
      "9           18   2025-04-12              6      2025-05-07  1.054780\n",
      "10          21   2024-02-01              6      2020-04-01  1.370403\n",
      "Matches saved. Total time: 0.0010505999744054861 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def quick_match(disease_data, no_disease_data, \n",
    "                disease_features, no_disease_features, \n",
    "                cov_inv, enable_deduplication=True):\n",
    "    matches = []\n",
    "    used_indices = set() if enable_deduplication else None\n",
    "    total_time = 0.0\n",
    "\n",
    "    for i in range(len(disease_data)):\n",
    "\n",
    "        disease_id = disease_data.iloc[i]['ID']\n",
    "        disease_date = disease_data.iloc[i]['date']\n",
    "        current_features = disease_features.iloc[i].values.reshape(1, -1)\n",
    "\n",
    "        mask = (no_disease_data['ID'] != disease_id)\n",
    "        if enable_deduplication:\n",
    "            mask &= (~no_disease_data.index.isin(used_indices))\n",
    "            \n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        candidates = no_disease_data[mask]\n",
    "        if candidates.empty:\n",
    "            continue\n",
    "        \n",
    "        end_time = time.perf_counter()\n",
    "        elapsed_time = end_time - start_time\n",
    "        total_time += elapsed_time\n",
    "\n",
    "# choose the matched target randomly\n",
    "        candidates = candidates.sample(frac=1)\n",
    "        first_candidate_idx = candidates.index[0]\n",
    "        \n",
    "        candidate_features = no_disease_features.loc[first_candidate_idx].values.reshape(1, -1)\n",
    "        distance = cdist(\n",
    "            current_features, \n",
    "            candidate_features, \n",
    "            metric='mahalanobis', \n",
    "            VI=cov_inv\n",
    "        )[0][0]\n",
    "\n",
    "        matches.append({\n",
    "            'Disease ID': disease_id,\n",
    "            'Disease Date': disease_date,\n",
    "            'no Disease ID': no_disease_data.loc[first_candidate_idx, 'ID'],\n",
    "            'no Disease Date': no_disease_data.loc[first_candidate_idx, 'date'],\n",
    "            'Distance': distance,\n",
    "        })\n",
    "\n",
    "        if enable_deduplication:\n",
    "            used_indices.add(first_candidate_idx)\n",
    "\n",
    "            \n",
    "    return pd.DataFrame(matches), total_time\n",
    "\n",
    "def main():\n",
    "    features = ['age', 'gender', 'blood_pressure', 'height', 'weight', 'BMI']\n",
    "    weights = np.array([0.2, 0.1, 0.3, 0.1, 0.1, 0.2])\n",
    "\n",
    "    X_disease = preprocess_data(df_disease, features)\n",
    "    X_no_disease = preprocess_data(df_no_disease, features)\n",
    "\n",
    "    disease_features, no_disease_features = standardize_features(\n",
    "        X_disease, X_no_disease, features\n",
    "    )\n",
    "\n",
    "    cov_inv = compute_weighted_covariance(\n",
    "        disease_features, no_disease_features, weights\n",
    "    )\n",
    "\n",
    "    matches_df, total_time = quick_match(\n",
    "        disease_data=X_disease,\n",
    "        no_disease_data=X_no_disease,\n",
    "        disease_features=disease_features,\n",
    "        no_disease_features=no_disease_features,\n",
    "        cov_inv=cov_inv,\n",
    "        enable_deduplication=True\n",
    "    )\n",
    "\n",
    "    matches_df.to_csv(\"quick_match.csv\", index=False)\n",
    "    print(matches_df.head(20))\n",
    "    print(f\"Matches saved. Total time: {total_time} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "88583705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Disease ID Disease Date  no Disease ID no Disease Date  Distance\n",
      "0           4   2022-09-30              2      2020-09-28  0.686888\n",
      "1           7   2021-03-08             22      2020-11-18  0.331066\n",
      "2          21   2024-02-01              2      2020-09-28  0.298963\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "df_disease = pd.read_csv(\"male_disease.csv\")\n",
    "df_no_disease = pd.read_csv(\"male_no_disease.csv\")\n",
    "\n",
    "def preprocess_data(df, features):\n",
    "    df = df.copy()\n",
    "    df_clean = df.dropna(subset=features).reset_index(drop=True)\n",
    "    return df_clean\n",
    "\n",
    "# standardization\n",
    "def standardize_features(disease_df, no_disease_df, features):\n",
    "    combined = pd.concat([disease_df[features], no_disease_df[features]])\n",
    "    mean = combined.mean()\n",
    "    std = combined.std()\n",
    "\n",
    "    disease_features = (disease_df[features] - mean) / std\n",
    "    no_disease_features = (no_disease_df[features] - mean) / std\n",
    "    return disease_features, no_disease_features\n",
    "\n",
    "# compute the weighted covariance matrix\n",
    "def compute_weighted_covariance(disease_features, no_disease_features, weights):\n",
    "\n",
    "    combined = pd.concat([disease_features, no_disease_features])\n",
    "    cov_matrix = combined.cov().values\n",
    "\n",
    "    W_matrix = np.outer(weights, weights)\n",
    "    cov_weighted = cov_matrix / W_matrix\n",
    "\n",
    "    try:\n",
    "        cov_inv = np.linalg.inv(cov_weighted)\n",
    "    except np.linalg.LinAlgError:\n",
    "        cov_inv = np.linalg.pinv(cov_weighted)\n",
    "    return cov_inv\n",
    "\n",
    "\n",
    "def exact_matches(disease_data, no_disease_data, \n",
    "                disease_features, no_disease_features, \n",
    "                cov_inv, enable_deduplication=True):\n",
    "    matches = []\n",
    "    used_indices = set() if enable_deduplication else None\n",
    "    \n",
    "    for i in range(len(disease_data)):\n",
    "        disease_id = disease_data.iloc[i]['ID']\n",
    "        disease_date = disease_data.iloc[i]['date']\n",
    "        current_features = disease_features.iloc[i].values.reshape(1, -1)\n",
    "\n",
    "        mask = (no_disease_data['ID'] != disease_id)\n",
    "        if enable_deduplication:\n",
    "            mask &= (~no_disease_data.index.isin(used_indices))\n",
    "            \n",
    "        candidates = no_disease_data[mask]\n",
    "        if candidates.empty:\n",
    "            continue\n",
    "\n",
    "        distances = cdist(\n",
    "            current_features, \n",
    "            no_disease_features[mask], \n",
    "            metric='mahalanobis', \n",
    "            VI=cov_inv\n",
    "        )\n",
    "\n",
    "        min_idx = np.argmin(distances)\n",
    "        best_match_idx = candidates.index[min_idx]\n",
    "# record the matched results\n",
    "        record = {\n",
    "            'Disease ID': disease_id,\n",
    "            'Disease Date': disease_date,\n",
    "            'no Disease ID': no_disease_data.loc[best_match_idx, 'ID'],\n",
    "            'no Disease Date': no_disease_data.loc[best_match_idx, 'date'],\n",
    "            'Distance': distances[0, min_idx]\n",
    "        }\n",
    "        matches.append(record)\n",
    "\n",
    "        if enable_deduplication:\n",
    "            used_indices.add(best_match_idx)\n",
    "            \n",
    "    return pd.DataFrame(matches)\n",
    "\n",
    "def main():\n",
    "\n",
    "    features = ['age', 'blood_pressure', 'height', 'weight', 'BMI']\n",
    "    weights = np.array([0.2, 0.3, 0.1, 0.2, 0.2])\n",
    "    output_path = \"male_exact_match.csv\"\n",
    "\n",
    "    X_disease = preprocess_data(df_disease, features)\n",
    "    X_no_disease = preprocess_data(df_no_disease, features)\n",
    "\n",
    "    disease_features, no_disease_features = standardize_features(\n",
    "        X_disease, X_no_disease, features\n",
    "    )\n",
    "\n",
    "    cov_inv = compute_weighted_covariance(\n",
    "        disease_features, no_disease_features, weights\n",
    "    )\n",
    "\n",
    "    matches_df = exact_matches(\n",
    "        disease_data=X_disease,\n",
    "        no_disease_data=X_no_disease,\n",
    "        disease_features=disease_features,\n",
    "        no_disease_features=no_disease_features,\n",
    "        cov_inv=cov_inv,\n",
    "        enable_deduplication=False\n",
    "    )\n",
    "\n",
    "    matches_df.to_csv(output_path, index=False)\n",
    "    print(matches_df.head(20))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ac2f770b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Disease ID Disease Date  no Disease ID no Disease Date  Distance\n",
      "0           3   2020-05-30             19      2020-08-18  0.510398\n",
      "1           3   2024-05-23             19      2020-08-18  0.460687\n",
      "2           3   2025-04-21             19      2020-10-17  0.577145\n",
      "3          10   2020-06-19             19      2020-12-25  0.426859\n",
      "4          13   2025-05-31              5      2025-05-15  0.318579\n",
      "5          17   2021-01-28              5      2025-05-15  0.304208\n",
      "6          18   2023-01-01             19      2020-04-24  0.262519\n",
      "7          18   2025-04-12             19      2020-04-24  0.400112\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "df_disease = pd.read_csv(\"female_disease.csv\")\n",
    "df_no_disease = pd.read_csv(\"female_no_disease.csv\")\n",
    "\n",
    "def preprocess_data(df, features):\n",
    "    df = df.copy()\n",
    "    df_clean = df.dropna(subset=features).reset_index(drop=True)\n",
    "    return df_clean\n",
    "\n",
    "# standardization\n",
    "def standardize_features(disease_df, no_disease_df, features):\n",
    "    combined = pd.concat([disease_df[features], no_disease_df[features]])\n",
    "    mean = combined.mean()\n",
    "    std = combined.std()\n",
    "\n",
    "    disease_features = (disease_df[features] - mean) / std\n",
    "    no_disease_features = (no_disease_df[features] - mean) / std\n",
    "    return disease_features, no_disease_features\n",
    "\n",
    "# compute the weighted covariance matrix\n",
    "def compute_weighted_covariance(disease_features, no_disease_features, weights):\n",
    "\n",
    "    combined = pd.concat([disease_features, no_disease_features])\n",
    "    cov_matrix = combined.cov().values\n",
    "\n",
    "    W_matrix = np.outer(weights, weights)\n",
    "    cov_weighted = cov_matrix / W_matrix\n",
    "\n",
    "    try:\n",
    "        cov_inv = np.linalg.inv(cov_weighted)\n",
    "    except np.linalg.LinAlgError:\n",
    "        cov_inv = np.linalg.pinv(cov_weighted)\n",
    "    return cov_inv\n",
    "\n",
    "\n",
    "def exact_matches(disease_data, no_disease_data, \n",
    "                disease_features, no_disease_features, \n",
    "                cov_inv, enable_deduplication=True):\n",
    "    matches = []\n",
    "    used_indices = set() if enable_deduplication else None\n",
    "    \n",
    "    for i in range(len(disease_data)):\n",
    "        disease_id = disease_data.iloc[i]['ID']\n",
    "        disease_date = disease_data.iloc[i]['date']\n",
    "        current_features = disease_features.iloc[i].values.reshape(1, -1)\n",
    "\n",
    "        mask = (no_disease_data['ID'] != disease_id)\n",
    "        if enable_deduplication:\n",
    "            mask &= (~no_disease_data.index.isin(used_indices))\n",
    "            \n",
    "        candidates = no_disease_data[mask]\n",
    "        if candidates.empty:\n",
    "            continue\n",
    "\n",
    "        distances = cdist(\n",
    "            current_features, \n",
    "            no_disease_features[mask], \n",
    "            metric='mahalanobis', \n",
    "            VI=cov_inv\n",
    "        )\n",
    "\n",
    "        min_idx = np.argmin(distances)\n",
    "        best_match_idx = candidates.index[min_idx]\n",
    "# record the matched results\n",
    "        record = {\n",
    "            'Disease ID': disease_id,\n",
    "            'Disease Date': disease_date,\n",
    "            'no Disease ID': no_disease_data.loc[best_match_idx, 'ID'],\n",
    "            'no Disease Date': no_disease_data.loc[best_match_idx, 'date'],\n",
    "            'Distance': distances[0, min_idx]\n",
    "        }\n",
    "        matches.append(record)\n",
    "\n",
    "        if enable_deduplication:\n",
    "            used_indices.add(best_match_idx)\n",
    "            \n",
    "    return pd.DataFrame(matches)\n",
    "\n",
    "def main():\n",
    "\n",
    "    features = ['age', 'blood_pressure', 'height', 'weight', 'BMI']\n",
    "    weights = np.array([0.2, 0.3, 0.1, 0.2, 0.2])\n",
    "    output_path = \"female_exact_match.csv\"\n",
    "\n",
    "    X_disease = preprocess_data(df_disease, features)\n",
    "    X_no_disease = preprocess_data(df_no_disease, features)\n",
    "\n",
    "    disease_features, no_disease_features = standardize_features(\n",
    "        X_disease, X_no_disease, features\n",
    "    )\n",
    "\n",
    "    cov_inv = compute_weighted_covariance(\n",
    "        disease_features, no_disease_features, weights\n",
    "    )\n",
    "\n",
    "    matches_df = exact_matches(\n",
    "        disease_data=X_disease,\n",
    "        no_disease_data=X_no_disease,\n",
    "        disease_features=disease_features,\n",
    "        no_disease_features=no_disease_features,\n",
    "        cov_inv=cov_inv,\n",
    "        enable_deduplication=False\n",
    "    )\n",
    "\n",
    "    matches_df.to_csv(output_path, index=False)\n",
    "    print(matches_df.head(20))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6466e6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Truncating to smaller size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "暴力枚举进度 (n=11):   0%|          | 0/39916800 [00:00<?] 内存：,      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "暴力枚举进度 (n=11): |          | 40478900/? [1:23:30<00:00] 内存：,           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "用户中断！当前最优解总距离： 7.389363006955237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mengh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3678: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "from itertools import permutations\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import sys\n",
    "import psutil\n",
    "\n",
    "df_disease = pd.read_csv(\"disease.csv\")\n",
    "df_no_disease = pd.read_csv(\"no_disease.csv\")\n",
    "\n",
    "def preprocess_data(df, features):\n",
    "    df = df.copy()\n",
    "    df['gender'] = df['gender'].map({'female': 0, 'male': 1})\n",
    "    return df[features + ['ID', 'date']]\n",
    "\n",
    "# standardization\n",
    "def standardize_features(disease_df, no_disease_df, features):\n",
    "    combined = pd.concat([disease_df[features], no_disease_df[features]])\n",
    "    mean = combined.mean()\n",
    "    std = combined.std()\n",
    "\n",
    "    disease_features = (disease_df[features] - mean) / std\n",
    "    no_disease_features = (no_disease_df[features] - mean) / std\n",
    "    return disease_features, no_disease_features\n",
    "\n",
    "# compute the weighted covariance matrix\n",
    "def compute_weighted_covariance(disease_features, no_disease_features, weights):\n",
    "\n",
    "    combined = pd.concat([disease_features, no_disease_features])\n",
    "    cov_matrix = combined.cov().values\n",
    "\n",
    "    W_matrix = np.outer(weights, weights)\n",
    "    cov_weighted = cov_matrix / W_matrix\n",
    "\n",
    "    try:\n",
    "        cov_inv = np.linalg.inv(cov_weighted)\n",
    "    except np.linalg.LinAlgError:\n",
    "        cov_inv = np.linalg.pinv(cov_weighted)\n",
    "    return cov_inv\n",
    "\n",
    "# 内存监控函数\n",
    "def get_mem_usage():\n",
    "    process = psutil.Process()\n",
    "    return f\"{process.memory_info().rss / 1024 ** 2:.1f}MB\"\n",
    "\n",
    "def exact_matches(disease_data, no_disease_data, \n",
    "                disease_features, no_disease_features, \n",
    "                cov_inv):\n",
    "    n = len(disease_data)\n",
    "    matches = []\n",
    "\n",
    "    # 计算全量距离矩阵\n",
    "    distance_matrix = cdist(\n",
    "        disease_features, \n",
    "        no_disease_features,\n",
    "        metric='mahalanobis', \n",
    "        VI=cov_inv\n",
    "    )\n",
    "\n",
    "    min_total = float('inf')\n",
    "    best_perm = None\n",
    "    \n",
    "    # 安全阈值检查\n",
    "    MAX_PERMS = 40_000_000  # 最多允许处理1百万次排列\n",
    "    if math.factorial(n) > MAX_PERMS:\n",
    "        raise ValueError(f\"n={n}的排列数超过安全阈值{MAX_PERMS:,}\")\n",
    "    \n",
    "    # 进度条配置\n",
    "    total_perms = math.factorial(n)\n",
    "    progress_bar = tqdm(\n",
    "        total=total_perms,\n",
    "        desc=f\"暴力枚举进度 (n={n})\",\n",
    "        unit=\"perm\",\n",
    "        bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}] 内存：{postfix[0]}\",\n",
    "        postfix=[get_mem_usage()]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        for perm in permutations(range(n)):\n",
    "            # 计算当前排列的总距离\n",
    "            total_distance = sum(distance_matrix[i, perm[i]] for i in range(n))\n",
    "            \n",
    "            # 保留最优解\n",
    "            if total_distance < min_total:\n",
    "                min_total = total_distance\n",
    "                best_perm = perm\n",
    "            \n",
    "            # 每100次更新一次进度条\n",
    "            if progress_bar.n % 100 == 0:\n",
    "                progress_bar.set_postfix_str(get_mem_usage())\n",
    "                progress_bar.update(100)\n",
    "                \n",
    "        # 处理最后剩余部分\n",
    "        if progress_bar.n < total_perms:\n",
    "            progress_bar.update(total_perms - progress_bar.n)\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n用户中断！当前最优解总距离：\", min_total)\n",
    "        sys.exit(1)\n",
    "    finally:\n",
    "        progress_bar.close()\n",
    "\n",
    "    # 构建匹配结果\n",
    "    for i in range(n):\n",
    "        disease_row = disease_data.iloc[i]\n",
    "        no_disease_row = no_disease_data.iloc[best_perm[i]]\n",
    "        \n",
    "        record = {\n",
    "            'Disease ID': disease_row['ID'],\n",
    "            'Disease Date': disease_row['date'],\n",
    "            'no Disease ID': no_disease_row['ID'],\n",
    "            'no Disease Date': no_disease_row['date'],\n",
    "            'Distance': distance_matrix[i, best_perm[i]]\n",
    "        }\n",
    "        matches.append(record)\n",
    "        \n",
    "    return pd.DataFrame(matches)\n",
    "\n",
    "def main():\n",
    "\n",
    "    features = ['age', 'gender', 'blood_pressure', 'height', 'weight', 'BMI']\n",
    "    weights = np.array([0.2, 0.1, 0.3, 0.1, 0.1, 0.2])\n",
    "    output_path = \"optimal_match.csv\"\n",
    "\n",
    "    X_disease = preprocess_data(df_disease, features)\n",
    "    X_no_disease = preprocess_data(df_no_disease, features)\n",
    "\n",
    "    disease_features, no_disease_features = standardize_features(\n",
    "        X_disease, X_no_disease, features\n",
    "    )\n",
    "\n",
    "    cov_inv = compute_weighted_covariance(\n",
    "        disease_features, no_disease_features, weights\n",
    "    )\n",
    "\n",
    "    \n",
    "    if len(X_disease) != len(X_no_disease):\n",
    "        print(\"Warning: Truncating to smaller size\")\n",
    "        min_len = min(len(X_disease), len(X_no_disease))\n",
    "        X_disease = X_disease.iloc[:min_len]\n",
    "        X_no_disease = X_no_disease.iloc[:min_len]\n",
    "\n",
    "    matches_df = exact_matches(\n",
    "        disease_data=X_disease,\n",
    "        no_disease_data=X_no_disease,\n",
    "        disease_features=disease_features,\n",
    "        no_disease_features=no_disease_features,\n",
    "        cov_inv=cov_inv,\n",
    "    )\n",
    "\n",
    "    matches_df.to_csv(output_path, index=False)\n",
    "    print(matches_df.head(20))\n",
    "\n",
    "    total_distance = matches_df['Distance'].sum()\n",
    "    print(\"Total distance:\", total_distance)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4f66dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "暴力枚举 (n=11): 100%|██████████| 39916800/39916800 [03:45<00:00, 177080.18it/s] 内存：,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'to_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 162\u001b[39m\n\u001b[32m    159\u001b[39m     matches_df.to_csv(\u001b[33m\"\u001b[39m\u001b[33mbrute_force_results.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 159\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# 执行匹配\u001b[39;00m\n\u001b[32m    154\u001b[39m matches_df = exact_matches(\n\u001b[32m    155\u001b[39m     X_disease, X_no_disease, \n\u001b[32m    156\u001b[39m     disease_features, no_disease_features, \n\u001b[32m    157\u001b[39m     cov_inv\n\u001b[32m    158\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m \u001b[43mmatches_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbrute_force_results.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:3956\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3797\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m   3798\u001b[39m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(\n\u001b[32m   3799\u001b[39m     version=\u001b[33m\"\u001b[39m\u001b[33m3.0\u001b[39m\u001b[33m\"\u001b[39m, allowed_args=[\u001b[33m\"\u001b[39m\u001b[33mself\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpath_or_buf\u001b[39m\u001b[33m\"\u001b[39m], name=\u001b[33m\"\u001b[39m\u001b[33mto_csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3827\u001b[39m     storage_options: StorageOptions | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   3828\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3829\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3830\u001b[39m \u001b[33;03m    Write object to a comma-separated values (csv) file.\u001b[39;00m\n\u001b[32m   3831\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3954\u001b[39m \u001b[33;03m    >>> df.to_csv('folder/subfolder/out.csv')  # doctest: +SKIP\u001b[39;00m\n\u001b[32m   3955\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3956\u001b[39m     df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mto_frame\u001b[49m()\n\u001b[32m   3958\u001b[39m     formatter = DataFrameFormatter(\n\u001b[32m   3959\u001b[39m         frame=df,\n\u001b[32m   3960\u001b[39m         header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3964\u001b[39m         decimal=decimal,\n\u001b[32m   3965\u001b[39m     )\n\u001b[32m   3967\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter).to_csv(\n\u001b[32m   3968\u001b[39m         path_or_buf,\n\u001b[32m   3969\u001b[39m         lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3983\u001b[39m         storage_options=storage_options,\n\u001b[32m   3984\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'to_frame'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "from itertools import permutations\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import sys\n",
    "import time  # 新增时间模块\n",
    "import psutil\n",
    "\n",
    "# --------------------------\n",
    "# 数据预处理函数（保持不变）\n",
    "# --------------------------\n",
    "def preprocess_data(df, features):\n",
    "    df = df.copy()\n",
    "    df['gender'] = df['gender'].map({'female': 0, 'male': 1})\n",
    "    return df[features + ['ID', 'date']]\n",
    "\n",
    "def standardize_features(disease_df, no_disease_df, features):\n",
    "    disease_idx = disease_df.index\n",
    "    no_disease_idx = no_disease_df.index\n",
    "    \n",
    "    combined = pd.concat([disease_df[features], no_disease_df[features]])\n",
    "    mean = combined.mean()\n",
    "    std = combined.std()\n",
    "    disease_features = (disease_df[features] - mean) / std\n",
    "    no_disease_features = (no_disease_df[features] - mean) / std\n",
    "\n",
    "    disease_features.index = disease_idx\n",
    "    no_disease_features.index = no_disease_idx\n",
    "    return disease_features, no_disease_features\n",
    "\n",
    "def compute_weighted_covariance(disease_features, no_disease_features, weights):\n",
    "    combined = pd.concat([disease_features, no_disease_features])\n",
    "    cov_matrix = combined.cov().values\n",
    "    W_matrix = np.outer(weights, weights)\n",
    "    cov_weighted = cov_matrix / W_matrix\n",
    "    try:\n",
    "        cov_inv = np.linalg.inv(cov_weighted)\n",
    "    except np.linalg.LinAlgError:\n",
    "        cov_inv = np.linalg.pinv(cov_weighted)\n",
    "    return cov_inv\n",
    "\n",
    "# --------------------------\n",
    "# 暴力枚举匹配算法（优化版）\n",
    "# --------------------------\n",
    "def exact_matches(disease_data, no_disease_data, \n",
    "                disease_features, no_disease_features, \n",
    "                cov_inv):\n",
    "    n = len(disease_data)\n",
    "    matches = []\n",
    "\n",
    "    # 计算全量距离矩阵（优化存储）\n",
    "    distance_matrix = cdist(\n",
    "        disease_features.values.astype(np.float32),  # 使用单精度浮点节省内存\n",
    "        no_disease_features.values.astype(np.float32),\n",
    "        metric='mahalanobis',\n",
    "        VI=cov_inv.astype(np.float32)\n",
    "    )\n",
    "    no_disease_data = no_disease_data.reset_index(drop=True)\n",
    "    no_disease_features = no_disease_features.reset_index(drop=True)\n",
    "\n",
    "    min_total = float('inf')\n",
    "    best_perm = None\n",
    "    indices = np.arange(n)  # 预生成索引\n",
    "    \n",
    "    # 安全阈值检查\n",
    "    MAX_PERMS = 10**8\n",
    "    if math.factorial(n) > MAX_PERMS:\n",
    "        raise ValueError(f\"排列数超过安全阈值 {MAX_PERMS}\")\n",
    "\n",
    "    # 进度条配置\n",
    "    progress_bar = tqdm(\n",
    "        permutations(range(n)),\n",
    "        total=math.factorial(n),\n",
    "        desc=f\"暴力枚举 (n={n})\",\n",
    "        bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}] 内存：{postfix[0]}\",\n",
    "        postfix=[psutil.Process().memory_info().rss // 1024**2]\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        for perm in progress_bar:\n",
    "            # 向量化计算总距离\n",
    "            total_distance = distance_matrix[indices, list(perm)].sum()\n",
    "            \n",
    "            if total_distance < min_total:\n",
    "                min_total = total_distance\n",
    "                best_perm = perm\n",
    "            \n",
    "            # 每100次更新内存和预计时间\n",
    "            if progress_bar.n % 100 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                per_perm = elapsed / (progress_bar.n + 1)\n",
    "                remaining = per_perm * (progress_bar.total - progress_bar.n)\n",
    "                progress_bar.set_postfix(\n",
    "                    mem_mb=psutil.Process().memory_info().rss // 1024**2,\n",
    "                    est_remain=f\"{remaining:.1f}s\"\n",
    "                )\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"\\n用户中断！当前最小总距离：{min_total:.2f}\")\n",
    "        sys.exit(1)\n",
    "    finally:\n",
    "        progress_bar.close()\n",
    "    for i in range(n):\n",
    "        disease_row = disease_data.iloc[i]\n",
    "        no_disease_row = no_disease_data.iloc[best_perm[i]]\n",
    "        \n",
    "        record = {\n",
    "            'Disease ID': disease_row['ID'],\n",
    "            'Disease Date': disease_row['date'],\n",
    "            'no Disease ID': no_disease_row['ID'],\n",
    "            'no Disease Date': no_disease_row['date'],\n",
    "            'Distance': distance_matrix[i, best_perm[i]]\n",
    "        }\n",
    "        matches.append(record)\n",
    "\n",
    "    # 构建结果（略，同原代码）\n",
    "    return pd.DataFrame\n",
    "\n",
    "# --------------------------\n",
    "# 主函数（添加安全限制）\n",
    "# --------------------------\n",
    "def main():\n",
    "    # 数据加载\n",
    "    df_disease = pd.read_csv(\"disease.csv\")\n",
    "    df_no_disease = pd.read_csv(\"no_disease.csv\")\n",
    "\n",
    "    # 预处理\n",
    "    features = ['age', 'gender', 'blood_pressure', 'height', 'weight', 'BMI']\n",
    "    X_disease = preprocess_data(df_disease, features)\n",
    "    X_no_disease = preprocess_data(df_no_disease, features)\n",
    "\n",
    "    # 强制规模限制\n",
    "    MAX_SAFE_SAMPLES = 15  # 最大允许暴力计算的样本数\n",
    "    min_len = min(len(X_disease), len(X_no_disease))\n",
    "    if min_len > MAX_SAFE_SAMPLES:\n",
    "        print(f\"错误：数据规模 {min_len} 超过安全阈值 {MAX_SAFE_SAMPLES}\")\n",
    "        sys.exit(1)\n",
    "    X_disease = X_disease.iloc[:MAX_SAFE_SAMPLES]\n",
    "    X_no_disease = X_no_disease.iloc[:MAX_SAFE_SAMPLES]\n",
    "\n",
    "    # 标准化与协方差计算\n",
    "    disease_features, no_disease_features = standardize_features(\n",
    "        X_disease, X_no_disease, features\n",
    "    )\n",
    "    cov_inv = compute_weighted_covariance(\n",
    "        disease_features, no_disease_features, \n",
    "        weights=np.array([0.2, 0.1, 0.3, 0.1, 0.1, 0.2])\n",
    "    )\n",
    "\n",
    "    # 执行匹配\n",
    "    matches_df = exact_matches(\n",
    "        X_disease, X_no_disease, \n",
    "        disease_features, no_disease_features, \n",
    "        cov_inv\n",
    "    )\n",
    "    matches_df.to_csv(\"brute_force_results.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
